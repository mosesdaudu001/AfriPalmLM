# AfriPalmLM
The Finetuning of the PalmLM LLM, which is a 1.7B model with multilingual dataset

Process:
* Process Data (Data is processed within notebook environment because we can't store on Github - 0.99GB)
* Train Tokenizer (270,000 and 70,000)
* Build Model
* Evaluate Model

To train the tokenizer, kindly check the notebook section for the tokenizer trainer notebook. (ToDo: Convert notebook to pythin script)
